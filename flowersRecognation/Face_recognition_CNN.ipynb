{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8D_BeYEaHOF",
        "outputId": "8bc57a12-e8de-43c9-a7ec-f03ecae3777d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGkyJMfLSo5U",
        "outputId": "2ee52e54-1331-48fe-a3f5-2a2a23e9d4e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install tflearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjccTCacPonx",
        "outputId": "867856c6-61e8-4deb-a2b2-a14166df6586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ2IDDsSQSH6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from googleport cv2_ims.colab.patches imhow #Because cv2.imshow is no more supported by colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6X6o_ChSdVO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnfzTUKKVbQV"
      },
      "outputs": [],
      "source": [
        "face_test = cv2.imread('/content/drive/MyDrive/face recognition project/face_test.png', cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(face_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F2yV4_jR7FM"
      },
      "source": [
        "# Generating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-xIyFVORORk"
      },
      "outputs": [],
      "source": [
        "#Check this https://www.youtube.com/watch?v=LopYA64KmdE\n",
        "def generate_dataset():\n",
        "    face_classifier = cv2.CascadeClassifier(\"/content/drive/MyDrive/face recognition project/haarcascade_frontalface_default.xml\")\n",
        "    def face_cropped(img):\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "        \n",
        "        if faces == ():\n",
        "            return None\n",
        "        for (x,y,w,h) in faces:\n",
        "            cropped_face = img[y:y+h,x:x+w]\n",
        "        return cropped_face\n",
        "    \n",
        "    cap = cv2.VideoCapture(\"/content/drive/MyDrive/2_people_video.mp4\")\n",
        "    img_id = 0\n",
        "    \n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if face_cropped(frame) is not None:\n",
        "            img_id+=1\n",
        "            face = cv2.resize(face_cropped(frame), (200,200))\n",
        "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "            file_name_path = \"/content/drive/MyDrive/data/\"+\"Ishwar.\"+str(img_id)+\".jpg\"\n",
        "            #file_name_path = \"/content/drive/MyDrive/Images for visualization/\"+str(img_id)+'.jpg'\n",
        "            cv2.imwrite(file_name_path, face)\n",
        "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\n",
        "            \n",
        "            cv2_imshow(face)\n",
        "            if cv2.waitKey(1)==13 or int(img_id)==20:\n",
        "                break\n",
        "                \n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Collecting samples is completed !!!\")\n",
        "#generate_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7HOriFFnonq",
        "outputId": "3bdd11cd-f17e-46b5-cbf2-0bc0ef9dc780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting samples is completed !!!\n"
          ]
        }
      ],
      "source": [
        "generate_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz1VKqbTR_26"
      },
      "source": [
        "# Create label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrZnkMs5Rxtp"
      },
      "outputs": [],
      "source": [
        "import numpy as np # pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anucriiXSFOu"
      },
      "outputs": [],
      "source": [
        "def my_label(image_name):\n",
        "    name = image_name.split('.')[-3] \n",
        "    # if you have two person in your dataset\n",
        "    if name==\"Ishwar\":\n",
        "        return np.array([1,0])\n",
        "    elif name==\"Manish\":\n",
        "        return np.array([0,1])\n",
        "    \n",
        "    \n",
        "    # # if you have three person in your dataset\n",
        "    # if name==\"Ishwar\":\n",
        "    #     return np.array([1,0,0])\n",
        "    # elif name==\"Manish\":\n",
        "    #     return np.array([0,1,0])\n",
        "    # elif name==\"Bijay\":\n",
        "    #     return np.array([0,0,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKhylQnASLty"
      },
      "source": [
        "# Create data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKar18m-SI0Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from random import shuffle\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5uP_0oGSPZO"
      },
      "outputs": [],
      "source": [
        "def my_data():\n",
        "    data = []\n",
        "    for i in range(1,21):\n",
        "      img=\"/content/drive/MyDrive/face recognition project/data/\"+\"Ishwar.\"+str(i)+\".jpg\"\n",
        "      img_data = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
        "      img_data.resize((50,50))\n",
        "      data.append([np.array(img_data), my_label(img)])\n",
        "    shuffle(data)  \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv4_7XsKSWZC"
      },
      "outputs": [],
      "source": [
        "data = my_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXbwSo7YScVc",
        "outputId": "d8ee223d-f596-468a-fea5-2d75d285e149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15, 50, 50, 1)\n",
            "(15, 50, 50, 1)\n"
          ]
        }
      ],
      "source": [
        "train = data[:15]  \n",
        "test = data[5:]\n",
        "X_train = np.array([i[0] for i in train]).reshape(-1,50,50,1)\n",
        "print(X_train.shape)\n",
        "y_train = [i[1] for i in train]\n",
        "X_test = np.array([i[0] for i in test]).reshape(-1,50,50,1)\n",
        "print(X_test.shape)\n",
        "y_test = [i[1] for i in test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMwFaJqcwUiU",
        "outputId": "fc8ed661-d57b-4883-a4d3-400611b39d0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNOP_a4lSfLT"
      },
      "source": [
        "# Creating the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_8V8F4tBSx_K",
        "outputId": "f71fa4cd-1ac6-4259-e78c-3521633e0491"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-251-faa805b403bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mconvnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_verbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"FRS\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# asynchronous feed dict allocation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# TODO: check memory impact for large data and multiple optimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         feed_dict = feed_dict_builder(X_inputs, Y_targets, self.inputs,\n\u001b[0m\u001b[1;32m    184\u001b[0m                                       self.targets)\n\u001b[1;32m    185\u001b[0m         \u001b[0mfeed_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tflearn/utils.py\u001b[0m in \u001b[0;36mfeed_dict_builder\u001b[0;34m(X, Y, net_inputs, net_targets)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                 \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# If a dict is provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# tf.reset_default_graph()\n",
        "convnet = input_data(shape=[50,50,1])\n",
        "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "# 32 filters and stride=5 so that the filter will move 5 pixel or unit at a time\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "convnet = fully_connected(convnet, 1024, activation='relu')\n",
        "convnet = dropout(convnet, 0.8)\n",
        "convnet = fully_connected(convnet, 3, activation='softmax')\n",
        "convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossentropy')\n",
        "model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
        "model.fit(X_train, y_train, n_epoch=12, validation_set=(X_test, y_test), show_metric = True, run_id=\"FRS\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La_H70JgS0Sx"
      },
      "source": [
        "# Visualization & Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5lDaDT2S5TQ"
      },
      "outputs": [],
      "source": [
        "def data_for_visualization():\n",
        "    Vdata = []\n",
        "    for img in tqdm(os.listdir(\"/content/drive/MyDrive/face recognition project/Images for visualization\")):\n",
        "        path = os.path.join(\"/content/drive/MyDrive/face recognition project/Images for visualization\", img)\n",
        "        img_num = img.split('.')[0] \n",
        "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img_data = cv2.resize(img_data, (50,50))\n",
        "        Vdata.append([np.array(img_data), img_num])\n",
        "    shuffle(Vdata)\n",
        "    return Vdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpDcCJtXS71J"
      },
      "outputs": [],
      "source": [
        "Vdata = data_for_visualization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWiGMyynS9Ve"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt   # pip install matplotlib\n",
        "\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "for num, data in enumerate(Vdata[:20]):\n",
        "    img_data = data[0]\n",
        "    y = fig.add_subplot(5,5, num+1)\n",
        "    image = img_data\n",
        "    data = img_data.reshape(50,50,1)\n",
        "    model_out = model.predict([data])[0]\n",
        "    \n",
        "    if np.argmax(model_out) == 0:\n",
        "        my_label = 'Ishwar'\n",
        "    elif np.argmax(model_out) == 1:\n",
        "        my_label = 'Manish'\n",
        "    else:\n",
        "        my_label = 'Bijay'\n",
        "        \n",
        "    y.imshow(image, cmap='gray')\n",
        "    plt.title(my_label)\n",
        "    \n",
        "    y.axes.get_xaxis().set_visible(False)\n",
        "    y.axes.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
