{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe7cad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "884b44e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/tmp/ipykernel_2176/3783814370.py:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "def generate_dataset(name):\n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    def face_cropped(img):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.1, 9)\n",
    "        \n",
    "        if faces is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_face = img[y:y+h,x:x+w]\n",
    "        return cropped_face\n",
    "\n",
    "    cap = cv2.VideoCapture(-1)\n",
    "    img_id = 0\n",
    "\n",
    "    os.mkdir(\"data/\"+name)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if face_cropped(frame) is not None:\n",
    "            img_id+=1\n",
    "            face = cv2.resize(face_cropped(frame), (200,200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            file_name_path = \"data/\"+name+\"/\"+str(img_id)+'.jpg'\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\n",
    "            \n",
    "            cv2.imshow(\"Cropped_Face\", face)\n",
    "            if cv2.waitKey(1)==13 or int(img_id)==100:\n",
    "                break\n",
    "                \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853c5a08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generate_dataset(\u001b[39m\"\u001b[39m\u001b[39mlahcen\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "generate_dataset(\"lahcen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64c029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "639d0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_lable(directories):\n",
    "    nb= len(directories)\n",
    "    return np.identity(nb).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e3d1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_lables=[]\n",
    "labels = os.listdir(\"data\")\n",
    "def dataSet():\n",
    "    data=[]\n",
    "    code_lables=code_lable(labels)\n",
    "    print(labels)\n",
    "    print(code_lables)\n",
    "    index_lable=0\n",
    "    for folder in labels:\n",
    "        for img in os.listdir(os.path.join(\"data\",folder)):\n",
    "            img_data = cv2.imread(os.path.join(\"data\",folder,img), cv2.IMREAD_GRAYSCALE)\n",
    "            img_data = cv2.resize(img_data, (50,50))\n",
    "            data.append([np.array(img_data), code_lables[index_lable]])\n",
    "        index_lable=index_lable+1\n",
    "    shuffle(data)  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55901927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['issam', 'fouad']\n",
      "[[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "data = dataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383904d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['issam', 'fouad']\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "160\n",
      "(160, 50, 50, 1)\n",
      "(40, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "data = dataSet()\n",
    "print(int(len(data)*0.8))\n",
    "train = data[:int(len(data)*0.8)]  \n",
    "test = data[int(len(data)*0.8):]\n",
    "#for t in test:\n",
    "#    print(t[1])\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1,50,50,1)\n",
    "print(X_train.shape)\n",
    "y_train = [i[1] for i in train]\n",
    "\n",
    "X_test = np.array([i[0] for i in test]).reshape(-1,50,50,1)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_test = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d8a512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 19:26:26.572501: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-04 19:26:27.225814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elbf/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-04 19:26:27.225841: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-04 19:26:28.805911: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elbf/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-04 19:26:28.806015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elbf/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-04 19:26:28.806027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/elbf/.local/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6658e308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.146s\n",
      "| Adam | epoch: 020 | loss: 0.00043 - acc: 0.9999 -- iter: 128/160\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m1.05255\u001b[0m\u001b[0m | time: 1.208s\n",
      "| Adam | epoch: 020 | loss: 1.05255 - acc: 0.9296 | val_loss: 0.00007 - val_acc: 1.0000 -- iter: 160/160\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "convnet = input_data(shape=[50,50,1])\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "# 32 filters and stride=5 so that the filter will move 5 pixel or unit at a time\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "#convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "#convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 512, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossentropy')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, n_epoch=20, validation_set=(X_test, y_test), show_metric = True, run_id=\"FRS\" )\n",
    "\n",
    "#model.save(\"my_model.tflearn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e23a102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/tmp/ipykernel_2527/1479739304.py:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7319826  0.26801747]]\n",
      "0\n",
      "issam\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model.load(\"my_model.tflearn\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def face_cropped(img):\n",
    "    faces = face_classifier.detectMultiScale(img, 1.1, 9)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h,x:x+w]\n",
    "    return cropped_face\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "y = fig.add_subplot(5,5, 1)\n",
    "\n",
    "img_data = cv2.imread(\"img.jpeg\", cv2.IMREAD_GRAYSCALE)\n",
    "#img_data = cv2.resize(img_data, (50,50))\n",
    "img_data = cv2.resize(face_cropped(img_data), (50,50))\n",
    "\n",
    "y.imshow(img_data, cmap='gray')\n",
    "y.axes.get_xaxis().set_visible(False)\n",
    "y.axes.get_yaxis().set_visible(False)\n",
    "#img = cv2.imread(\"img2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "#face = cv2.resize(face_cropped(img), (200,200))\n",
    "#face = cv2.resize(face, (50,50))\n",
    "#cv2.imshow(\"image\",face)\n",
    "\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "pred = model.predict([np.array(img_data).reshape(50,50,1)])\n",
    "print(pred)\n",
    "print(np.argmax(pred))\n",
    "print(labels[np.argmax(pred)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5846b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
